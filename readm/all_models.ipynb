{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions for calculating auroc and auprc and 95% CI's\n",
    "def roc_auc_ci(y_true, y_score, positive=1):\n",
    "    AUC = roc_auc_score(y_true, y_score)\n",
    "    N1 = sum(y_true == positive)\n",
    "    N2 = sum(y_true != positive)\n",
    "    Q1 = AUC / (2 - AUC)\n",
    "    Q2 = 2*AUC**2 / (1 + AUC)\n",
    "    SE_AUC = sqrt((AUC*(1 - AUC) + (N1 - 1)*(Q1 - AUC**2) + (N2 - 1)*(Q2 - AUC**2)) / (N1*N2))\n",
    "    lower = AUC - 1.96*SE_AUC\n",
    "    upper = AUC + 1.96*SE_AUC\n",
    "    if lower < 0:\n",
    "        lower = 0\n",
    "    if upper > 1:\n",
    "        upper = 1\n",
    "    return (lower, AUC, upper)\n",
    "def roc_prc_ci(y_true, y_score, positive=1):\n",
    "    AUC = average_precision_score(y_true, y_score)\n",
    "    N1 = sum(y_true == positive)\n",
    "    N2 = sum(y_true != positive)\n",
    "    Q1 = AUC / (2 - AUC)\n",
    "    Q2 = 2*AUC**2 / (1 + AUC)\n",
    "    SE_AUC = sqrt((AUC*(1 - AUC) + (N1 - 1)*(Q1 - AUC**2) + (N2 - 1)*(Q2 - AUC**2)) / (N1*N2))\n",
    "    lower = AUC - 1.96*SE_AUC\n",
    "    upper = AUC + 1.96*SE_AUC\n",
    "    if lower < 0:\n",
    "        lower = 0\n",
    "    if upper > 1:\n",
    "        upper = 1\n",
    "    return (lower, AUC, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the training and test data\n",
    "data = pd.read_feather(r'/media/kchen/2TB/kchen_backup/readm/data/procol_train.feather')\n",
    "y = data['READMISSION1']\n",
    "X = data.drop(['READMISSION1','CASEID'], axis=1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "test = pd.read_feather(r'/media/kchen/2TB/kchen_backup/readm/data/procol_test.feather')\n",
    "y_test = test['READMISSION1']\n",
    "X_test = test.drop(['READMISSION1','CASEID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-12 13:35:48.778132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 13:35:48.784767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 13:35:48.785272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 13:35:48.785825: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-12 13:35:48.786291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 13:35:48.786685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 13:35:48.787049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 13:35:49.264541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 13:35:49.264987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 13:35:49.265361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 13:35:49.265717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10091 MB memory:  -> device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1\n",
      "2022-01-12 13:35:49.950297: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 153270656 exceeds 10% of free system memory.\n",
      "2022-01-12 13:35:50.078399: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 153270656 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "335/335 [==============================] - 3s 6ms/step - loss: 0.3709 - Sensitivity: 0.0281 - tn: 150578.0000 - auc: 0.6220 - prc: 0.1652 - val_loss: 0.4613 - val_Sensitivity: 0.0201 - val_tn: 38156.0000 - val_auc: 0.6777 - val_prc: 0.2457\n",
      "Epoch 2/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3279 - Sensitivity: 0.0210 - tn: 152111.0000 - auc: 0.6724 - prc: 0.2180 - val_loss: 0.3167 - val_Sensitivity: 0.0405 - val_tn: 38182.0000 - val_auc: 0.7035 - val_prc: 0.2918\n",
      "Epoch 3/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3210 - Sensitivity: 0.0413 - tn: 152129.0000 - auc: 0.6860 - prc: 0.2565 - val_loss: 0.3101 - val_Sensitivity: 0.0633 - val_tn: 38167.0000 - val_auc: 0.7159 - val_prc: 0.3140\n",
      "Epoch 4/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3154 - Sensitivity: 0.0608 - tn: 152149.0000 - auc: 0.6949 - prc: 0.2844 - val_loss: 0.3056 - val_Sensitivity: 0.0819 - val_tn: 38129.0000 - val_auc: 0.7161 - val_prc: 0.3183\n",
      "Epoch 5/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3110 - Sensitivity: 0.0771 - tn: 152130.0000 - auc: 0.7014 - prc: 0.3034 - val_loss: 0.3036 - val_Sensitivity: 0.0871 - val_tn: 38136.0000 - val_auc: 0.7210 - val_prc: 0.3261\n",
      "Epoch 6/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3088 - Sensitivity: 0.0847 - tn: 152104.0000 - auc: 0.7059 - prc: 0.3107 - val_loss: 0.3022 - val_Sensitivity: 0.1011 - val_tn: 38100.0000 - val_auc: 0.7214 - val_prc: 0.3275\n",
      "Epoch 7/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3066 - Sensitivity: 0.0916 - tn: 152083.0000 - auc: 0.7105 - prc: 0.3204 - val_loss: 0.3006 - val_Sensitivity: 0.1025 - val_tn: 38088.0000 - val_auc: 0.7225 - val_prc: 0.3284\n",
      "Epoch 8/200\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 0.3054 - Sensitivity: 0.0931 - tn: 152129.0000 - auc: 0.7129 - prc: 0.3234 - val_loss: 0.2999 - val_Sensitivity: 0.1027 - val_tn: 38106.0000 - val_auc: 0.7228 - val_prc: 0.3325\n",
      "Epoch 9/200\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 0.3047 - Sensitivity: 0.0968 - tn: 152102.0000 - auc: 0.7134 - prc: 0.3270 - val_loss: 0.2995 - val_Sensitivity: 0.1145 - val_tn: 38034.0000 - val_auc: 0.7236 - val_prc: 0.3324\n",
      "Epoch 10/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3040 - Sensitivity: 0.1020 - tn: 152082.0000 - auc: 0.7145 - prc: 0.3307 - val_loss: 0.2984 - val_Sensitivity: 0.1066 - val_tn: 38099.0000 - val_auc: 0.7235 - val_prc: 0.3343\n",
      "Epoch 11/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3031 - Sensitivity: 0.1042 - tn: 152112.0000 - auc: 0.7167 - prc: 0.3337 - val_loss: 0.2983 - val_Sensitivity: 0.1101 - val_tn: 38087.0000 - val_auc: 0.7265 - val_prc: 0.3370\n",
      "Epoch 12/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3026 - Sensitivity: 0.1060 - tn: 152098.0000 - auc: 0.7182 - prc: 0.3354 - val_loss: 0.2986 - val_Sensitivity: 0.1077 - val_tn: 38098.0000 - val_auc: 0.7237 - val_prc: 0.3363\n",
      "Epoch 13/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3034 - Sensitivity: 0.1022 - tn: 152111.0000 - auc: 0.7161 - prc: 0.3335 - val_loss: 0.2977 - val_Sensitivity: 0.1103 - val_tn: 38086.0000 - val_auc: 0.7259 - val_prc: 0.3380\n",
      "Epoch 14/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3016 - Sensitivity: 0.1086 - tn: 152074.0000 - auc: 0.7197 - prc: 0.3392 - val_loss: 0.2977 - val_Sensitivity: 0.1064 - val_tn: 38107.0000 - val_auc: 0.7270 - val_prc: 0.3396\n",
      "Epoch 15/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3016 - Sensitivity: 0.1085 - tn: 152106.0000 - auc: 0.7201 - prc: 0.3411 - val_loss: 0.2969 - val_Sensitivity: 0.1127 - val_tn: 38084.0000 - val_auc: 0.7271 - val_prc: 0.3406\n",
      "Epoch 16/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3015 - Sensitivity: 0.1112 - tn: 152084.0000 - auc: 0.7205 - prc: 0.3402 - val_loss: 0.2970 - val_Sensitivity: 0.1103 - val_tn: 38096.0000 - val_auc: 0.7257 - val_prc: 0.3386\n",
      "Epoch 17/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3013 - Sensitivity: 0.1087 - tn: 152081.0000 - auc: 0.7204 - prc: 0.3399 - val_loss: 0.2977 - val_Sensitivity: 0.1112 - val_tn: 38106.0000 - val_auc: 0.7266 - val_prc: 0.3418\n",
      "Epoch 18/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3012 - Sensitivity: 0.1105 - tn: 152108.0000 - auc: 0.7202 - prc: 0.3404 - val_loss: 0.2969 - val_Sensitivity: 0.1130 - val_tn: 38092.0000 - val_auc: 0.7266 - val_prc: 0.3385\n",
      "Epoch 19/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3011 - Sensitivity: 0.1110 - tn: 152094.0000 - auc: 0.7212 - prc: 0.3399 - val_loss: 0.2967 - val_Sensitivity: 0.1081 - val_tn: 38122.0000 - val_auc: 0.7287 - val_prc: 0.3423\n",
      "Epoch 20/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3012 - Sensitivity: 0.1098 - tn: 152085.0000 - auc: 0.7216 - prc: 0.3418 - val_loss: 0.2965 - val_Sensitivity: 0.1103 - val_tn: 38113.0000 - val_auc: 0.7286 - val_prc: 0.3411\n",
      "Epoch 21/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3006 - Sensitivity: 0.1132 - tn: 152104.0000 - auc: 0.7213 - prc: 0.3442 - val_loss: 0.2970 - val_Sensitivity: 0.1184 - val_tn: 38044.0000 - val_auc: 0.7274 - val_prc: 0.3402\n",
      "Epoch 22/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2999 - Sensitivity: 0.1162 - tn: 152064.0000 - auc: 0.7233 - prc: 0.3458 - val_loss: 0.2964 - val_Sensitivity: 0.1116 - val_tn: 38100.0000 - val_auc: 0.7279 - val_prc: 0.3409\n",
      "Epoch 23/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3003 - Sensitivity: 0.1123 - tn: 152089.0000 - auc: 0.7234 - prc: 0.3453 - val_loss: 0.2971 - val_Sensitivity: 0.1130 - val_tn: 38104.0000 - val_auc: 0.7266 - val_prc: 0.3410\n",
      "Epoch 24/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.3001 - Sensitivity: 0.1159 - tn: 152072.0000 - auc: 0.7229 - prc: 0.3466 - val_loss: 0.2966 - val_Sensitivity: 0.1114 - val_tn: 38106.0000 - val_auc: 0.7281 - val_prc: 0.3425\n",
      "Epoch 25/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2994 - Sensitivity: 0.1144 - tn: 152059.0000 - auc: 0.7253 - prc: 0.3483 - val_loss: 0.2965 - val_Sensitivity: 0.1101 - val_tn: 38107.0000 - val_auc: 0.7278 - val_prc: 0.3418\n",
      "Epoch 26/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2996 - Sensitivity: 0.1164 - tn: 152078.0000 - auc: 0.7244 - prc: 0.3473 - val_loss: 0.2961 - val_Sensitivity: 0.1084 - val_tn: 38121.0000 - val_auc: 0.7292 - val_prc: 0.3449\n",
      "Epoch 27/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2993 - Sensitivity: 0.1186 - tn: 152058.0000 - auc: 0.7254 - prc: 0.3478 - val_loss: 0.2959 - val_Sensitivity: 0.1132 - val_tn: 38103.0000 - val_auc: 0.7293 - val_prc: 0.3438\n",
      "Epoch 28/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2994 - Sensitivity: 0.1166 - tn: 152077.0000 - auc: 0.7247 - prc: 0.3479 - val_loss: 0.2961 - val_Sensitivity: 0.1143 - val_tn: 38093.0000 - val_auc: 0.7291 - val_prc: 0.3435\n",
      "Epoch 29/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2985 - Sensitivity: 0.1181 - tn: 152050.0000 - auc: 0.7281 - prc: 0.3512 - val_loss: 0.2962 - val_Sensitivity: 0.1158 - val_tn: 38083.0000 - val_auc: 0.7288 - val_prc: 0.3426\n",
      "Epoch 30/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2990 - Sensitivity: 0.1183 - tn: 152042.0000 - auc: 0.7262 - prc: 0.3492 - val_loss: 0.2964 - val_Sensitivity: 0.1077 - val_tn: 38123.0000 - val_auc: 0.7281 - val_prc: 0.3436\n",
      "Epoch 31/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2987 - Sensitivity: 0.1182 - tn: 152071.0000 - auc: 0.7273 - prc: 0.3506 - val_loss: 0.2959 - val_Sensitivity: 0.1158 - val_tn: 38096.0000 - val_auc: 0.7290 - val_prc: 0.3437\n",
      "Epoch 32/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2989 - Sensitivity: 0.1168 - tn: 152073.0000 - auc: 0.7274 - prc: 0.3491 - val_loss: 0.2967 - val_Sensitivity: 0.1127 - val_tn: 38103.0000 - val_auc: 0.7279 - val_prc: 0.3421\n",
      "Epoch 33/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2985 - Sensitivity: 0.1157 - tn: 152049.0000 - auc: 0.7290 - prc: 0.3504 - val_loss: 0.2962 - val_Sensitivity: 0.1132 - val_tn: 38096.0000 - val_auc: 0.7286 - val_prc: 0.3428\n",
      "Epoch 34/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2982 - Sensitivity: 0.1182 - tn: 152053.0000 - auc: 0.7284 - prc: 0.3529 - val_loss: 0.2962 - val_Sensitivity: 0.1141 - val_tn: 38096.0000 - val_auc: 0.7286 - val_prc: 0.3438\n",
      "Epoch 35/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2980 - Sensitivity: 0.1176 - tn: 152060.0000 - auc: 0.7293 - prc: 0.3517 - val_loss: 0.2966 - val_Sensitivity: 0.1123 - val_tn: 38112.0000 - val_auc: 0.7276 - val_prc: 0.3433\n",
      "Epoch 36/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2982 - Sensitivity: 0.1186 - tn: 152062.0000 - auc: 0.7297 - prc: 0.3517 - val_loss: 0.2966 - val_Sensitivity: 0.1046 - val_tn: 38135.0000 - val_auc: 0.7283 - val_prc: 0.3456\n",
      "Epoch 37/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2980 - Sensitivity: 0.1193 - tn: 152088.0000 - auc: 0.7292 - prc: 0.3543 - val_loss: 0.2965 - val_Sensitivity: 0.1114 - val_tn: 38115.0000 - val_auc: 0.7279 - val_prc: 0.3437\n",
      "Epoch 38/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2978 - Sensitivity: 0.1175 - tn: 152083.0000 - auc: 0.7296 - prc: 0.3547 - val_loss: 0.2958 - val_Sensitivity: 0.1147 - val_tn: 38093.0000 - val_auc: 0.7292 - val_prc: 0.3434\n",
      "Epoch 39/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2976 - Sensitivity: 0.1202 - tn: 152067.0000 - auc: 0.7310 - prc: 0.3544 - val_loss: 0.2964 - val_Sensitivity: 0.1130 - val_tn: 38110.0000 - val_auc: 0.7278 - val_prc: 0.3425\n",
      "Epoch 40/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2971 - Sensitivity: 0.1233 - tn: 152073.0000 - auc: 0.7309 - prc: 0.3585 - val_loss: 0.2961 - val_Sensitivity: 0.1095 - val_tn: 38121.0000 - val_auc: 0.7281 - val_prc: 0.3443\n",
      "Epoch 41/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2979 - Sensitivity: 0.1185 - tn: 152074.0000 - auc: 0.7296 - prc: 0.3552 - val_loss: 0.2960 - val_Sensitivity: 0.1088 - val_tn: 38121.0000 - val_auc: 0.7284 - val_prc: 0.3441\n",
      "Epoch 42/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2974 - Sensitivity: 0.1176 - tn: 152059.0000 - auc: 0.7315 - prc: 0.3567 - val_loss: 0.2954 - val_Sensitivity: 0.1112 - val_tn: 38124.0000 - val_auc: 0.7299 - val_prc: 0.3463\n",
      "Epoch 43/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2968 - Sensitivity: 0.1218 - tn: 152075.0000 - auc: 0.7324 - prc: 0.3570 - val_loss: 0.2960 - val_Sensitivity: 0.1160 - val_tn: 38091.0000 - val_auc: 0.7290 - val_prc: 0.3452\n",
      "Epoch 44/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2973 - Sensitivity: 0.1201 - tn: 152062.0000 - auc: 0.7320 - prc: 0.3561 - val_loss: 0.2964 - val_Sensitivity: 0.1103 - val_tn: 38123.0000 - val_auc: 0.7286 - val_prc: 0.3447\n",
      "Epoch 45/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2965 - Sensitivity: 0.1197 - tn: 152061.0000 - auc: 0.7348 - prc: 0.3581 - val_loss: 0.2959 - val_Sensitivity: 0.1132 - val_tn: 38106.0000 - val_auc: 0.7285 - val_prc: 0.3431\n",
      "Epoch 46/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2965 - Sensitivity: 0.1224 - tn: 152056.0000 - auc: 0.7337 - prc: 0.3597 - val_loss: 0.2961 - val_Sensitivity: 0.1116 - val_tn: 38115.0000 - val_auc: 0.7290 - val_prc: 0.3454\n",
      "Epoch 47/200\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.2967 - Sensitivity: 0.1216 - tn: 152070.0000 - auc: 0.7335 - prc: 0.3586 - val_loss: 0.2963 - val_Sensitivity: 0.1077 - val_tn: 38129.0000 - val_auc: 0.7293 - val_prc: 0.3463\n",
      "Epoch 48/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2961 - Sensitivity: 0.1227 - tn: 152057.0000 - auc: 0.7345 - prc: 0.3606 - val_loss: 0.2964 - val_Sensitivity: 0.1114 - val_tn: 38115.0000 - val_auc: 0.7267 - val_prc: 0.3428\n",
      "Epoch 49/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2965 - Sensitivity: 0.1214 - tn: 152066.0000 - auc: 0.7335 - prc: 0.3601 - val_loss: 0.2959 - val_Sensitivity: 0.1114 - val_tn: 38120.0000 - val_auc: 0.7286 - val_prc: 0.3455\n",
      "Epoch 50/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2964 - Sensitivity: 0.1234 - tn: 152048.0000 - auc: 0.7338 - prc: 0.3619 - val_loss: 0.2958 - val_Sensitivity: 0.1165 - val_tn: 38097.0000 - val_auc: 0.7289 - val_prc: 0.3456\n",
      "Epoch 51/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2957 - Sensitivity: 0.1225 - tn: 152015.0000 - auc: 0.7363 - prc: 0.3625 - val_loss: 0.2959 - val_Sensitivity: 0.1108 - val_tn: 38117.0000 - val_auc: 0.7286 - val_prc: 0.3456\n",
      "Epoch 52/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2960 - Sensitivity: 0.1228 - tn: 152053.0000 - auc: 0.7352 - prc: 0.3620 - val_loss: 0.2955 - val_Sensitivity: 0.1132 - val_tn: 38115.0000 - val_auc: 0.7297 - val_prc: 0.3467\n",
      "Epoch 53/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2959 - Sensitivity: 0.1238 - tn: 152081.0000 - auc: 0.7349 - prc: 0.3627 - val_loss: 0.2960 - val_Sensitivity: 0.1151 - val_tn: 38109.0000 - val_auc: 0.7282 - val_prc: 0.3443\n",
      "Epoch 54/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2955 - Sensitivity: 0.1226 - tn: 152021.0000 - auc: 0.7367 - prc: 0.3627 - val_loss: 0.2955 - val_Sensitivity: 0.1138 - val_tn: 38107.0000 - val_auc: 0.7292 - val_prc: 0.3468\n",
      "Epoch 55/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2958 - Sensitivity: 0.1204 - tn: 152063.0000 - auc: 0.7369 - prc: 0.3610 - val_loss: 0.2957 - val_Sensitivity: 0.1130 - val_tn: 38119.0000 - val_auc: 0.7289 - val_prc: 0.3464\n",
      "Epoch 56/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2949 - Sensitivity: 0.1278 - tn: 152006.0000 - auc: 0.7374 - prc: 0.3669 - val_loss: 0.2961 - val_Sensitivity: 0.1178 - val_tn: 38092.0000 - val_auc: 0.7276 - val_prc: 0.3435\n",
      "Epoch 57/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2949 - Sensitivity: 0.1243 - tn: 152016.0000 - auc: 0.7381 - prc: 0.3657 - val_loss: 0.2958 - val_Sensitivity: 0.1160 - val_tn: 38104.0000 - val_auc: 0.7290 - val_prc: 0.3443\n",
      "Epoch 58/200\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.2949 - Sensitivity: 0.1234 - tn: 152043.0000 - auc: 0.7380 - prc: 0.3656 - val_loss: 0.2959 - val_Sensitivity: 0.1180 - val_tn: 38082.0000 - val_auc: 0.7284 - val_prc: 0.3451\n",
      "Epoch 59/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2952 - Sensitivity: 0.1236 - tn: 152060.0000 - auc: 0.7378 - prc: 0.3646 - val_loss: 0.2963 - val_Sensitivity: 0.1119 - val_tn: 38119.0000 - val_auc: 0.7276 - val_prc: 0.3453\n",
      "Epoch 60/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2949 - Sensitivity: 0.1223 - tn: 152033.0000 - auc: 0.7396 - prc: 0.3669 - val_loss: 0.2959 - val_Sensitivity: 0.1176 - val_tn: 38087.0000 - val_auc: 0.7282 - val_prc: 0.3447\n",
      "Epoch 61/200\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.2953 - Sensitivity: 0.1259 - tn: 152051.0000 - auc: 0.7360 - prc: 0.3662 - val_loss: 0.2963 - val_Sensitivity: 0.1136 - val_tn: 38112.0000 - val_auc: 0.7279 - val_prc: 0.3443\n",
      "Epoch 62/200\n",
      "335/335 [==============================] - 2s 6ms/step - loss: 0.2942 - Sensitivity: 0.1281 - tn: 152022.0000 - auc: 0.7392 - prc: 0.3696 - val_loss: 0.2958 - val_Sensitivity: 0.1154 - val_tn: 38107.0000 - val_auc: 0.7285 - val_prc: 0.3456\n",
      "Epoch 63/200\n",
      "335/335 [==============================] - 2s 7ms/step - loss: 0.2946 - Sensitivity: 0.1274 - tn: 152034.0000 - auc: 0.7392 - prc: 0.3673 - val_loss: 0.2965 - val_Sensitivity: 0.1066 - val_tn: 38139.0000 - val_auc: 0.7274 - val_prc: 0.3448\n",
      "Epoch 64/200\n",
      "335/335 [==============================] - 2s 5ms/step - loss: 0.2945 - Sensitivity: 0.1270 - tn: 152033.0000 - auc: 0.7394 - prc: 0.3681 - val_loss: 0.2964 - val_Sensitivity: 0.1119 - val_tn: 38118.0000 - val_auc: 0.7276 - val_prc: 0.3447\n",
      "Epoch 65/200\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 0.2946 - Sensitivity: 0.1261 - tn: 152049.0000 - auc: 0.7389 - prc: 0.3679 - val_loss: 0.2962 - val_Sensitivity: 0.1156 - val_tn: 38089.0000 - val_auc: 0.7273 - val_prc: 0.3448\n",
      "Epoch 66/200\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 0.2942 - Sensitivity: 0.1275 - tn: 152013.0000 - auc: 0.7403 - prc: 0.3694 - val_loss: 0.2963 - val_Sensitivity: 0.1095 - val_tn: 38126.0000 - val_auc: 0.7275 - val_prc: 0.3448\n",
      "Epoch 67/200\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 0.2941 - Sensitivity: 0.1267 - tn: 152044.0000 - auc: 0.7405 - prc: 0.3693 - val_loss: 0.2968 - val_Sensitivity: 0.1110 - val_tn: 38116.0000 - val_auc: 0.7263 - val_prc: 0.3432\n",
      "Stored 'ann_fpr_readm' (ndarray)\n",
      "Stored 'ann_tpr_readm' (ndarray)\n",
      "Stored 'ann_prec_readm' (ndarray)\n",
      "Stored 'ann_rec_readm' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "#input shape is the shape of the training data\n",
    "input_shape = [X_train.shape[1]]\n",
    "#define NN model based on parameters from search_keras.py\n",
    "model4 = keras.models.Sequential()\n",
    "model4.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "model4.add(keras.layers.BatchNormalization())\n",
    "for _ in range(2):\n",
    "    model4.add(keras.layers.Dense(1000))\n",
    "    model4.add(keras.layers.BatchNormalization())\n",
    "    model4.add(keras.layers.Dropout(0.8))\n",
    "    model4.add(keras.layers.Activation(\"relu\"))\n",
    "model4.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=3e-3)\n",
    "\n",
    "metrics = [keras.metrics.Recall(name='Sensitivity'), keras.metrics.TrueNegatives(name='tn'), keras.metrics.AUC(name='auc'), keras.metrics.AUC(name='prc', curve='PR')]\n",
    "\n",
    "model4.compile(\n",
    "    optimizer=opt,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=metrics,)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=25,\n",
    "    min_delta=1e-6,\n",
    "    restore_best_weights=True,)\n",
    "\n",
    "history = model4.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=512,\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping],)\n",
    "#calculate the auroc and auprc for the test set\n",
    "ann_preds_readm = model4.predict(X_test)\n",
    "ann_auc_readm = roc_auc_ci(y_test, ann_preds_readm)\n",
    "ann_prc_readm = roc_prc_ci(y_test, ann_preds_readm)\n",
    "#store the tpr/fpr and precision/recall for curves\n",
    "ann_fpr_readm, ann_tpr_readm, _ = roc_curve(y_test, ann_preds_readm)\n",
    "%store ann_fpr_readm\n",
    "%store ann_tpr_readm\n",
    "ann_prec_readm, ann_rec_readm, _ = precision_recall_curve(y_test, ann_preds_readm)\n",
    "%store ann_prec_readm\n",
    "%store ann_rec_readm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_86652/3355569755.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrf_preds_readm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrf_auc_readm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_ci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_preds_readm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrf_prc_readm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_prc_ci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_preds_readm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0my_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mclasses_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mimask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0minv_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0minv_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#fit and calculate performance metrics for RF and XGB\n",
    "rf = RandomForestClassifier(n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features='sqrt', max_depth=20, bootstrap=False)\n",
    "rf.fit(X, y)\n",
    "rf_preds_readm = rf.predict_proba(X_test)[:,1]\n",
    "rf_auc_readm = roc_auc_ci(y_test, rf_preds_readm)\n",
    "rf_prc_readm = roc_prc_ci(y_test, rf_preds_readm)\n",
    "xgb = XGBClassifier(subsample=0.6, n_estimators=100, min_child_weight=10, max_depth=5, learning_rate=0.05, colsample_bytree=0.8)\n",
    "xgb.fit(X, y)\n",
    "xgb_preds_readm = xgb.predict_proba(X_test)[:,1]\n",
    "xgb_auc_readm = roc_auc_ci(y_test, xgb_preds_readm)\n",
    "xgb_prc_readm = roc_prc_ci(y_test, xgb_preds_readm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kchen/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6761935377159206, 0.6844288993941394, 0.6926642610723582)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit and calculate performance metrics for LR\n",
    "lr = LogisticRegression(max_iter=1000, penalty='none')\n",
    "lr.fit(X, y)\n",
    "lr_preds_readm = lr.predict_proba(X_test)[:,1]\n",
    "lr_auc_readm = roc_auc_ci(y_test, lr_preds_readm)\n",
    "lr_prc_readm = roc_prc_ci(y_test, lr_preds_readm)\n",
    "lr_auc_readm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'lr_fpr_readm' (ndarray)\n",
      "Stored 'lr_tpr_readm' (ndarray)\n",
      "Stored 'lr_prec_readm' (ndarray)\n",
      "Stored 'lr_rec_readm' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "#get fpr/tpr and precision/recall for curves\n",
    "lr_fpr_readm, lr_tpr_readm, _ = roc_curve(y_test, lr_preds_readm)\n",
    "%store lr_fpr_readm\n",
    "%store lr_tpr_readm\n",
    "lr_prec_readm, lr_rec_readm, _ = precision_recall_curve(y_test, lr_preds_readm)\n",
    "%store lr_prec_readm\n",
    "%store lr_rec_readm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'rf_fpr_readm' (ndarray)\n",
      "Stored 'rf_tpr_readm' (ndarray)\n",
      "Stored 'rf_prec_readm' (ndarray)\n",
      "Stored 'rf_rec_readm' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "rf_fpr_readm, rf_tpr_readm, _ = roc_curve(y_test, rf_preds_readm)\n",
    "%store rf_fpr_readm\n",
    "%store rf_tpr_readm\n",
    "rf_prec_readm, rf_rec_readm, _ = precision_recall_curve(y_test, rf_preds_readm)\n",
    "%store rf_prec_readm\n",
    "%store rf_rec_readm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'xgb_fpr_readm' (ndarray)\n",
      "Stored 'xgb_tpr_readm' (ndarray)\n",
      "Stored 'xgb_prec_readm' (ndarray)\n",
      "Stored 'xgb_rec_readm' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "xgb_fpr_readm, xgb_tpr_readm, _ = roc_curve(y_test, xgb_preds_readm)\n",
    "%store xgb_fpr_readm\n",
    "%store xgb_tpr_readm\n",
    "xgb_prec_readm, xgb_rec_readm, _ = precision_recall_curve(y_test, xgb_preds_readm)\n",
    "%store xgb_prec_readm\n",
    "%store xgb_rec_readm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write results to txt file\n",
    "with open('readm_results.txt', 'w') as f:\n",
    "    f.write('AUROC\\n')\n",
    "    f.write('LR: '+str(round(lr_auc_readm[1], 3))+' (95% CI'+str(round(lr_auc_readm[0], 3))+'-'+str(round(lr_auc_readm[2], 3))+')\\n')\n",
    "    f.write('RF: '+str(round(rf_auc_readm[1], 3))+' (95% CI'+str(round(rf_auc_readm[0], 3))+'-'+str(round(rf_auc_readm[2], 3))+')\\n')\n",
    "    f.write('XGB: '+str(round(xgb_auc_readm[1], 3))+' (95% CI'+str(round(xgb_auc_readm[0], 3))+'-'+str(round(xgb_auc_readm[2], 3))+')\\n')\n",
    "    f.write('NN: '+str(round(ann_auc_readm[1], 3))+' (95% CI'+str(round(ann_auc_readm[0], 3))+'-'+str(round(ann_auc_readm[2], 3))+')\\n')\n",
    "    f.write('AUPRC\\n')\n",
    "    f.write('LR: '+str(round(lr_prc_readm[1], 3))+' (95% CI'+str(round(lr_prc_readm[0], 3))+'-'+str(round(lr_prc_readm[2], 3))+')\\n')\n",
    "    f.write('RF: '+str(round(rf_prc_readm[1], 3))+' (95% CI'+str(round(rf_prc_readm[0], 3))+'-'+str(round(rf_prc_readm[2], 3))+')\\n')\n",
    "    f.write('XGB: '+str(round(xgb_prc_readm[1], 3))+' (95% CI'+str(round(xgb_prc_readm[0], 3))+'-'+str(round(xgb_prc_readm[2], 3))+')\\n')\n",
    "    f.write('NN: '+str(round(ann_prc_readm[1], 3))+' (95% CI'+str(round(ann_prc_readm[0], 3))+'-'+str(round(ann_prc_readm[2], 3))+')\\n')\n",
    "#write results to csv file\n",
    "with open('readm_results.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['model','AUROC mean', 'AUROC 95% CI', 'AUPRC mean', 'AUPRC 95% CI']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerow({'model':'Logistic Regression', 'AUROC mean':round(lr_auc_readm[1], 3), 'AUROC 95% CI':str(round(lr_auc_readm[0], 3))+'-'+str(round(lr_auc_readm[2], 3)), 'AUPRC mean':round(lr_prc_readm[1], 3), 'AUPRC 95% CI':str(round(lr_prc_readm[0], 3))+'-'+str(round(lr_prc_readm[2], 3))})\n",
    "    writer.writerow({'model':'Random Forest', 'AUROC mean':round(rf_auc_readm[1], 3), 'AUROC 95% CI':str(round(rf_auc_readm[0], 3))+'-'+str(round(rf_auc_readm[2], 3)), 'AUPRC mean':round(rf_prc_readm[1], 3), 'AUPRC 95% CI':str(round(rf_prc_readm[0], 3))+'-'+str(round(rf_prc_readm[2], 3))})\n",
    "    writer.writerow({'model':'XGBoost', 'AUROC mean':round(xgb_auc_readm[1], 3), 'AUROC 95% CI':str(round(xgb_auc_readm[0], 3))+'-'+str(round(xgb_auc_readm[2], 3)), 'AUPRC mean':round(xgb_prc_readm[1], 3), 'AUPRC 95% CI':str(round(xgb_prc_readm[0], 3))+'-'+str(round(xgb_prc_readm[2], 3))})\n",
    "    writer.writerow({'model':'Neural Network', 'AUROC mean':round(ann_auc_readm[1], 3), 'AUROC 95% CI':str(round(ann_auc_readm[0], 3))+'-'+str(round(ann_auc_readm[2], 3)), 'AUPRC mean':round(ann_prc_readm[1], 3), 'AUPRC 95% CI':str(round(ann_prc_readm[0], 3))+'-'+str(round(ann_prc_readm[2], 3))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias ann_preds_readm\n",
      "no stored variable or alias lr_preds_readm\n"
     ]
    }
   ],
   "source": [
    "#get p-value for ann vs lr using Delong method from https://biasedml.com/roc-comparison/\n",
    "%store -r ann_preds_readm\n",
    "%store -r lr_preds_readm\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as st\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_86652/4290855762.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovar_AB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def auc(X, Y):\n",
    "    return 1/(len(X)*len(Y)) * sum([kernel(x, y) for x in X for y in Y])\n",
    "def kernel(X, Y):\n",
    "    return .5 if Y==X else int(Y < X)\n",
    "def structural_components(X, Y):\n",
    "    V10 = [1/len(Y) * sum([kernel(x, y) for y in Y]) for x in X]\n",
    "    V01 = [1/len(X) * sum([kernel(x, y) for x in X]) for y in Y]\n",
    "    return V10, V01\n",
    "    \n",
    "\n",
    "def get_S_entry(V_A, V_B, auc_A, auc_B):\n",
    "    return 1/(len(V_A)-1) * sum([(a-auc_A)*(b-auc_B) for a,b in zip(V_A, V_B)])\n",
    "def z_score(var_A, var_B, covar_AB, auc_A, auc_B):\n",
    "    return (auc_A - auc_B)/((var_A + var_B - 2*covar_AB)**(.5))\n",
    "\n",
    "\n",
    "# Model A (random) vs. \"good\" model B\n",
    "\n",
    "preds_A = ann_preds_readm\n",
    "preds_B = lr_preds_readm\n",
    "actual = y_test\n",
    "\n",
    "actual = actual.array\n",
    "\n",
    "def group_preds_by_label(preds, actual):\n",
    "    X = [p for (p, a) in zip(preds, actual) if a]\n",
    "    Y = [p for (p, a) in zip(preds, actual) if not a]\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "X_A, Y_A = group_preds_by_label(preds_A, actual)\n",
    "X_B, Y_B = group_preds_by_label(preds_B, actual)\n",
    "V_A10, V_A01 = structural_components(X_A, Y_A)\n",
    "V_B10, V_B01 = structural_components(X_B, Y_B)\n",
    "auc_A = auc(X_A, Y_A)\n",
    "auc_B = auc(X_B, Y_B)\n",
    "\n",
    "\n",
    "# Compute entries of covariance matrix S (covar_AB = covar_BA)\n",
    "var_A = (get_S_entry(V_A10, V_A10, auc_A, auc_A) * 1/len(V_A10)\n",
    "        + get_S_entry(V_A01, V_A01, auc_A, auc_A) * 1/len(V_A01))\n",
    "var_B = (get_S_entry(V_B10, V_B10, auc_B, auc_B) * 1/len(V_B10)\n",
    "        + get_S_entry(V_B01, V_B01, auc_B, auc_B) * 1/len(V_B01))\n",
    "covar_AB = (get_S_entry(V_A10, V_B10, auc_A, auc_B) * 1/len(V_A10)\n",
    "            + get_S_entry(V_A01, V_B01, auc_A, auc_B) * 1/len(V_A01))\n",
    "\n",
    "# Two tailed test\n",
    "z = z_score(var_A, var_B, covar_AB, auc_A, auc_B)\n",
    "\n",
    "p = st.norm.sf(abs(z))*2\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the sensitivity and specificity of the NN model at thresholds\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.metrics import specificity_score\n",
    "\n",
    "thresh = np.arange(0, 1, 0.0001)\n",
    "#calculate sensitivity at thresholds\n",
    "lr_sens = {}\n",
    "for t in thresh:\n",
    "    lr_sens[t] = recall_score(y_test, lr_preds_readm > t)\n",
    "lr_spec = {}\n",
    "for t in thresh:\n",
    "    lr_spec[t] = specificity_score(y_test, lr_preds_readm > t)\n",
    "ann_sens = {}\n",
    "for t in thresh:\n",
    "    ann_sens[t] = recall_score(y_test, ann_preds_readm > t)\n",
    "ann_spec = {}\n",
    "for t in thresh:\n",
    "    ann_spec[t] = specificity_score(y_test, ann_preds_readm > t)\n",
    "def get_senspec(thresh):\n",
    "    print(lr_sens[thresh], lr_spec[thresh])\n",
    "    print(ann_sens[thresh], ann_spec[thresh])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the sensitivity at various thresholds of specificity\n",
    "def get_lrsenspec(thresh):\n",
    "    print(recall_score(y_test, lr_preds_readm > thresh), specificity_score(y_test, lr_preds_readm > thresh))\n",
    "def get_annsenspec(thresh):\n",
    "    print(recall_score(y_test, ann_preds_readm > thresh), specificity_score(y_test, ann_preds_readm > thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9671669793621013 0.10048637239607232\n"
     ]
    }
   ],
   "source": [
    "get_lrsenspec(0.0609)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9778611632270169 0.10048637239607232\n"
     ]
    }
   ],
   "source": [
    "get_annsenspec(0.02897)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8855534709193246 0.3007708543635863\n"
     ]
    }
   ],
   "source": [
    "get_lrsenspec(0.0748)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9185741088180113 0.3000137652564926\n"
     ]
    }
   ],
   "source": [
    "get_annsenspec(0.0414)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7675422138836773 0.5000458841883088\n"
     ]
    }
   ],
   "source": [
    "get_lrsenspec(0.08962)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181988742964352 0.5000229420941543\n"
     ]
    }
   ],
   "source": [
    "get_annsenspec(0.06106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5784240150093809 0.7003762503441314\n"
     ]
    }
   ],
   "source": [
    "get_lrsenspec(0.1105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6652908067542214 0.700674497568138\n"
     ]
    }
   ],
   "source": [
    "get_annsenspec(0.1068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2373358348968105 0.9007066164999541\n"
     ]
    }
   ],
   "source": [
    "get_lrsenspec(0.164)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39849906191369605 0.9008213269707259\n"
     ]
    }
   ],
   "source": [
    "get_annsenspec(0.1839)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
